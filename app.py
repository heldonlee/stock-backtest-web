import io
import zipfile
from dataclasses import dataclass
import numpy as np
import pandas as pd
import streamlit as st

REQUIRED_COLS = ["date", "open", "high", "low", "close", "volume"]

# -----------------------------
# Core logic (signal + backtest)
# -----------------------------
def compute_signal(df: pd.DataFrame, zf_min: float = 7.0, vol_multi: float = 2.0, idx: int = 3) -> pd.Series:
    """
    å¤åˆ»é€šè¾¾ä¿¡å…¬å¼ï¼š
    XG: YD AND LY4 AND HOLD3;

    df: å¿…é¡»åŒ…å«åˆ— ['open','high','low','close','volume']ï¼ŒæŒ‰æ—¥æœŸå‡åº
    è¿”å›ï¼šbool Seriesï¼ŒTrue è¡¨ç¤ºâ€œå½“å‰è¿™æ ¹Kçº¿æ»¡è¶³XGâ€
    """
    O = df["open"].astype(float)
    L = df["low"].astype(float)
    C = df["close"].astype(float)
    V = df["volume"].astype(float)

    # 1) å¼‚åŠ¨é˜³çº¿ï¼ˆå‘å‰ idx å¤©ï¼‰
    E_YANG = (C.shift(idx) > O.shift(idx))
    E_ZF = ((C.shift(idx) / O.shift(idx) - 1.0) * 100.0 >= zf_min)
    V_MA5 = V.rolling(5, min_periods=5).mean()
    E_VOL = (V.shift(idx) >= vol_multi * V_MA5.shift(idx))
    YD = E_YANG & E_ZF & E_VOL

    # 2) å¼‚åŠ¨é˜³çº¿ä¹‹å‰è¿ç»­4å¤©é˜³çº¿
    LY4 = (
        (C.shift(idx + 1) > O.shift(idx + 1)) &
        (C.shift(idx + 2) > O.shift(idx + 2)) &
        (C.shift(idx + 3) > O.shift(idx + 3)) &
        (C.shift(idx + 4) > O.shift(idx + 4))
    )

    # 3) å¼‚åŠ¨é˜³çº¿å3å¤©ï¼šä¸ç ´å¼‚åŠ¨é˜³çº¿å¼€ç›˜ä»· + ç¼©é‡
    O_YD = O.shift(idx)
    HOLD3 = (
        (L.shift(2) >= O_YD) & (V.shift(2) < V.shift(idx)) &
        (L.shift(1) >= O_YD) & (V.shift(1) < V.shift(idx)) &
        (L >= O_YD) & (V < V.shift(idx))
    )

    XG = (YD & LY4 & HOLD3).fillna(False)
    return XG


def backtest_single(
    df: pd.DataFrame,
    signal: pd.Series,
    entry: str = "next_open",
    hold_days: int = 5,
    fee_bps: float = 10.0,
    slippage_bps: float = 5.0,
    stop_loss: float | None = None,
    take_profit: float | None = None,
) -> pd.DataFrame:
    """
    å•æ ‡çš„é€ç¬”å›æµ‹ï¼š
    - ä¿¡å·æ—¥ t
    - é»˜è®¤ t+1 å¼€ç›˜ä¹°å…¥
    - é»˜è®¤æŒæœ‰ hold_days ä¸ªäº¤æ˜“æ—¥åï¼ˆå«ä¹°å…¥æ—¥ï¼‰æ”¶ç›˜å–å‡º
    - ç®€å•æ­¢æŸæ­¢ç›ˆï¼šè‹¥è§¦å‘åˆ™æŒ‰â€œè§¦å‘å½“æ—¥æ”¶ç›˜â€å–å‡ºï¼ˆä¿å®ˆå£å¾„å¯æ”¹ï¼‰
    """
    df = df.copy().sort_values("date").reset_index(drop=True)
    df["date"] = pd.to_datetime(df["date"])

    O = df["open"].astype(float)
    H = df["high"].astype(float)
    L = df["low"].astype(float)
    C = df["close"].astype(float)

    sig_idx = np.where(signal.values)[0]
    trades = []

    cost = (fee_bps + slippage_bps) / 10000.0  # å•è¾¹æˆæœ¬ï¼ˆæ‰‹ç»­è´¹+æ»‘ç‚¹ï¼‰

    for t in sig_idx:
        buy_i = t + 1
        if buy_i >= len(df):
            continue

        buy_px = O.iloc[buy_i] if entry == "next_open" else C.iloc[buy_i]
        sell_i = buy_i + hold_days - 1
        if sell_i >= len(df):
            continue

        win_slice = slice(buy_i, sell_i + 1)

        sell_px = C.iloc[sell_i]
        exit_reason = f"time_exit_{hold_days}d"

        # æ­¢æŸ
        if stop_loss is not None:
            stop_level = buy_px * (1.0 - stop_loss)
            lows = L.iloc[win_slice].values
            if np.nanmin(lows) <= stop_level:
                hit = int(np.where(lows <= stop_level)[0][0])
                sell_i = buy_i + hit
                sell_px = C.iloc[sell_i]
                exit_reason = f"stop_loss_{stop_loss:.2%}"

        # æ­¢ç›ˆï¼ˆè‹¥æ›´æ—©è§¦å‘åˆ™è¦†ç›–ï¼‰
        if take_profit is not None:
            take_level = buy_px * (1.0 + take_profit)
            highs = H.iloc[win_slice].values
            if np.nanmax(highs) >= take_level:
                hit = int(np.where(highs >= take_level)[0][0])
                cand_i = buy_i + hit
                if cand_i < sell_i:
                    sell_i = cand_i
                    sell_px = C.iloc[sell_i]
                    exit_reason = f"take_profit_{take_profit:.2%}"

        gross_ret = (sell_px / buy_px) - 1.0
        net_ret = gross_ret - 2 * cost  # åŒè¾¹æˆæœ¬

        trades.append(
            {
                "signal_date": df["date"].iloc[t],
                "entry_date": df["date"].iloc[buy_i],
                "exit_date": df["date"].iloc[sell_i],
                "entry_px": float(buy_px),
                "exit_px": float(sell_px),
                "hold_days": int((sell_i - buy_i) + 1),
                "gross_ret": float(gross_ret),
                "net_ret": float(net_ret),
                "exit_reason": exit_reason,
            }
        )

    return pd.DataFrame(trades)


def summarize_trades(trades: pd.DataFrame) -> dict:
    if trades is None or trades.empty:
        return {"n_trades": 0}

    r = trades["net_ret"].astype(float).fillna(0.0)
    win_rate = float((r > 0).mean())

    # é€ç¬”å¤åˆ©æƒç›Šæ›²çº¿æœ€å¤§å›æ’¤
    equity = (1 + r).cumprod()
    peak = equity.cummax()
    dd = (equity / peak) - 1
    mdd = float(dd.min()) if len(dd) else 0.0

    pos_sum = float(r[r > 0].sum())
    neg_sum = float((-r[r < 0]).sum())
    profit_factor = float(pos_sum / (neg_sum + 1e-12))

    return {
        "n_trades": int(len(trades)),
        "win_rate": win_rate,
        "avg_ret": float(r.mean()),
        "median_ret": float(r.median()),
        "p25_ret": float(r.quantile(0.25)),
        "p75_ret": float(r.quantile(0.75)),
        "max_ret": float(r.max()),
        "min_ret": float(r.min()),
        "profit_factor": profit_factor,
        "mdd_by_trades": mdd,
    }


# -----------------------------
# Data loading helpers
# -----------------------------
def normalize_df(df):
    """
    è‡ªåŠ¨æŠŠå¸¸è§Aè‚¡å­—æ®µå â†’ ç»Ÿä¸€æˆ:
    date, open, high, low, close, volume
    """
    col_map = {}

    for c in df.columns:
        cl = c.lower()
        if cl in ["date", "trade_date", "datetime", "äº¤æ˜“æ—¥æœŸ"]:
            col_map[c] = "date"
        elif cl in ["open", "open_price", "å¼€ç›˜", "å¼€ç›˜ä»·"]:
            col_map[c] = "open"
        elif cl in ["high", "high_price", "æœ€é«˜", "æœ€é«˜ä»·"]:
            col_map[c] = "high"
        elif cl in ["low", "low_price", "æœ€ä½", "æœ€ä½ä»·"]:
            col_map[c] = "low"
        elif cl in ["close", "close_price", "æ”¶ç›˜", "æ”¶ç›˜ä»·"]:
            col_map[c] = "close"
        elif cl in ["volume", "vol", "æˆäº¤é‡"]:
            col_map[c] = "volume"

    df = df.rename(columns=col_map)

    required = ["date", "open", "high", "low", "close", "volume"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing}")

    df = df[required].copy()
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date")
    return df



def read_csv_bytes(b: bytes) -> pd.DataFrame:
    # å°è¯• utf-8 / gbk
    for enc in ["utf-8", "utf-8-sig", "gbk"]:
        try:
            return pd.read_csv(io.BytesIO(b), encoding=enc)
        except Exception:
            continue
    return pd.read_csv(io.BytesIO(b))


def load_universe_from_upload(upload) -> dict:
    """
    æ”¯æŒï¼š
    - å•ä¸ª CSVï¼šè¿”å› {filename_without_ext: df}
    - ZIPï¼šzipå†…å¤šä¸ªcsv -> {symbol: df}
    """
    name = upload.name.lower()
    raw = upload.getvalue()

    data_map = {}

    if name.endswith(".csv"):
        df = read_csv_bytes(raw)
        df = normalize_df(df)
        symbol = upload.name.rsplit(".", 1)[0]
        data_map[symbol] = df
        return data_map

    if name.endswith(".zip"):
        z = zipfile.ZipFile(io.BytesIO(raw))
        for info in z.infolist():
            if info.filename.lower().endswith(".csv") and not info.is_dir():
                b = z.read(info.filename)
                df = read_csv_bytes(b)
                df = normalize_df(df)
                symbol = info.filename.split("/")[-1].rsplit(".", 1)[0]
                data_map[symbol] = df
        if not data_map:
            raise ValueError("ZIP é‡Œæ²¡æœ‰æ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ã€‚")
        return data_map

    raise ValueError("åªæ”¯æŒä¸Šä¼  CSV æˆ– ZIP(å†…å«å¤šä¸ªCSV)ã€‚")


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="é€šè¾¾ä¿¡å½¢æ€å›æµ‹å™¨ï¼ˆåˆå¯Œä¸­å›½å¼ï¼‰", layout="wide")
st.title("é€šè¾¾ä¿¡å½¢æ€å›æµ‹å™¨ï¼šè¿é˜³ + ç‚¸æ¿å¼‚åŠ¨é˜³çº¿ + 3å¤©ç¼©é‡ä¸ç ´å¼€ç›˜ä»·")

with st.expander("æ•°æ®è¦æ±‚ï¼ˆç‚¹å¼€çœ‹ï¼‰", expanded=False):
    st.markdown(
        """
- ä¸Šä¼  **CSV**ï¼ˆå•ç¥¨ï¼‰æˆ– **ZIP**ï¼ˆå¤šç¥¨ï¼Œzip å†…å¤šä¸ª csvï¼‰
- æ¯ä¸ª CSV è‡³å°‘åŒ…å«åˆ—ï¼š`date, open, high, low, close, volume`
- æ—¥æœŸæŒ‰æ—¥çº¿ï¼›å»ºè®®ç”¨**å‰å¤æƒ**æ•°æ®ï¼ˆå¦åˆ™åˆ†çº¢é€è½¬ä¼šæ‰­æ›²å½¢æ€ï¼‰
        """
    )

colA, colB = st.columns([1, 1])

with colA:
    st.subheader("â‘  ä¸Šä¼ æ•°æ®")
    upload = st.file_uploader("é€‰æ‹© CSV æˆ– ZIP", type=["csv", "zip"])

with colB:
    st.subheader("â‘¡ å‚æ•°ï¼ˆå¤åˆ¶ç²˜è´´å³å¯ï¼‰")
    zf_min = st.number_input("ZF_MINï¼ˆå¼‚åŠ¨é˜³çº¿æœ€ä½æ¶¨å¹…%ï¼‰", value=7.0, min_value=0.0, step=0.5)
    vol_multi = st.number_input("VOL_MULTIï¼ˆæ”¾é‡å€æ•°Ã—5æ—¥å‡é‡ï¼‰", value=2.0, min_value=0.1, step=0.1)
    idx = st.number_input("IDXï¼ˆå¼‚åŠ¨é˜³çº¿è·ç¦»å½“å‰å¤©æ•°ï¼‰", value=3, min_value=1, step=1)

    st.markdown("---")
    hold_days = st.number_input("æŒæœ‰å¤©æ•°ï¼ˆé»˜è®¤5ï¼‰", value=5, min_value=1, step=1)
    entry = st.selectbox("è¿›åœºæ–¹å¼", ["next_open", "next_close"], index=0)
    fee_bps = st.number_input("æ‰‹ç»­è´¹ï¼ˆå•è¾¹ï¼Œbpsï¼‰", value=10.0, min_value=0.0, step=1.0)
    slippage_bps = st.number_input("æ»‘ç‚¹ï¼ˆå•è¾¹ï¼Œbpsï¼‰", value=5.0, min_value=0.0, step=1.0)

    st.markdown("---")
    use_sl = st.checkbox("å¯ç”¨æ­¢æŸ", value=False)
    stop_loss = st.number_input("æ­¢æŸæ¯”ä¾‹ï¼ˆå¦‚ 0.06=6%ï¼‰", value=0.06, min_value=0.0, step=0.01) if use_sl else None

    use_tp = st.checkbox("å¯ç”¨æ­¢ç›ˆ", value=False)
    take_profit = st.number_input("æ­¢ç›ˆæ¯”ä¾‹ï¼ˆå¦‚ 0.2=20%ï¼‰", value=0.20, min_value=0.0, step=0.01) if use_tp else None

run = st.button("ğŸš€ å¼€å§‹å›æµ‹", type="primary", use_container_width=True)

if run:
    if not upload:
        st.error("è¯·å…ˆä¸Šä¼  CSV æˆ– ZIPã€‚")
        st.stop()

    try:
        data_map = load_universe_from_upload(upload)
    except Exception as e:
        st.error(f"è¯»å–æ•°æ®å¤±è´¥ï¼š{e}")
        st.stop()

    all_trades = []
    summary_rows = []

    st.info(f"å·²è½½å…¥æ ‡çš„æ•°ï¼š{len(data_map)}ã€‚å¼€å§‹è®¡ç®—ä¿¡å·ä¸å›æµ‹â€¦")

    for symbol, df in data_map.items():
        sig = compute_signal(df, zf_min=zf_min, vol_multi=vol_multi, idx=int(idx))
        trades = backtest_single(
            df, sig,
            entry=entry,
            hold_days=int(hold_days),
            fee_bps=float(fee_bps),
            slippage_bps=float(slippage_bps),
            stop_loss=stop_loss,
            take_profit=take_profit,
        )
        if not trades.empty:
            trades.insert(0, "symbol", symbol)
            all_trades.append(trades)

        stats = summarize_trades(trades)
        stats["symbol"] = symbol
        summary_rows.append(stats)

    trades_df = pd.concat(all_trades, ignore_index=True) if all_trades else pd.DataFrame()
    summary_df = pd.DataFrame(summary_rows).sort_values(["n_trades", "win_rate"], ascending=False)

    st.success("å›æµ‹å®Œæˆ âœ…")

    # Overall summary
    st.subheader("æ€»ä½“ç»Ÿè®¡ï¼ˆå…¨æ ‡çš„åˆå¹¶ï¼‰")
    overall = summarize_trades(trades_df) if not trades_df.empty else {"n_trades": 0}
    st.json(overall)

    # Tables
    c1, c2 = st.columns([1, 1])

    with c1:
        st.subheader("åˆ†æ ‡çš„ç»Ÿè®¡ï¼ˆsummaryï¼‰")
        st.dataframe(summary_df, use_container_width=True, height=420)
        st.download_button(
            "ä¸‹è½½ summary.csv",
            data=summary_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="summary.csv",
            mime="text/csv",
            use_container_width=True
        )

    with c2:
        st.subheader("é€ç¬”äº¤æ˜“æ˜ç»†ï¼ˆtradesï¼‰")
        st.dataframe(trades_df, use_container_width=True, height=420)
        st.download_button(
            "ä¸‹è½½ trades.csv",
            data=trades_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="trades.csv",
            mime="text/csv",
            use_container_width=True
        )

    # Year stats
    st.subheader("æŒ‰å¹´ä»½ç»Ÿè®¡ï¼ˆentry yearï¼‰")
    if trades_df.empty:
        st.warning("æ²¡æœ‰äº§ç”Ÿä»»ä½•äº¤æ˜“ï¼ˆn_trades=0ï¼‰ã€‚å¯ä»¥å°è¯•é™ä½é˜ˆå€¼æˆ–æ‰©å¤§æ•°æ®èŒƒå›´ã€‚")
    else:
        trades_df["year"] = pd.to_datetime(trades_df["entry_date"]).dt.year
        year_stats = trades_df.groupby("year", as_index=False).apply(
            lambda x: pd.Series(summarize_trades(x))
        ).reset_index(drop=True)
        st.dataframe(year_stats, use_container_width=True)
        st.download_button(
            "ä¸‹è½½ year_stats.csv",
            data=year_stats.to_csv(index=False).encode("utf-8-sig"),
            file_name="year_stats.csv",
            mime="text/csv",
            use_container_width=True
        )

